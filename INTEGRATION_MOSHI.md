# üé§ Int√©gration Moshi - Documentation Technique

## ‚úÖ Modifications R√©alis√©es

### 1. `src/audio_engine.py` - R√©√©criture Compl√®te

**Changements majeurs :**
- ‚úÖ Int√©gration de l'API Moshi officielle avec `moshi.models.loaders.MoshiLoader`
- ‚úÖ Utilisation du worker pour le streaming avec `feed_audio()` et `get_output()`
- ‚úÖ Sample rate fix√© √† **24000 Hz** (standard Moshi)
- ‚úÖ Device MPS (Metal) avec fallback automatique sur CPU
- ‚úÖ Conversion numpy ‚Üí torch tensor pour Moshi
- ‚úÖ Gestion robuste des erreurs avec fallback device

**Structure cl√© :**
```python
from moshi.models import loaders

# Chargement du mod√®le
self.loader = loaders.MoshiLoader(
    repo_id="kyutai/moshiko-pytorch-bf16",
    device=self.device,  # "mps" ou "cpu"
)
self.model = self.loader.load()
self.worker = self.model.get_worker()

# Streaming audio
tensor = torch.from_numpy(audio_data).to(self.device)
self.worker.feed_audio(tensor)
packet = self.worker.get_output()
```

### 2. `src/config.py` - Mise √† Jour Audio

**Changements :**
- ‚úÖ `sample_rate` : **24000 Hz** par d√©faut (au lieu de 16000)
- ‚úÖ `chunk_size` : **1920** par d√©faut (optimis√© pour 24000 Hz)

### 3. `src/brain_engine.py` - Am√©liorations Critiques

**Nouvelles fonctionnalit√©s :**
- ‚úÖ **Accumulation intelligente** : Ne pas envoyer chaque mot, accumule jusqu'√† phrase compl√®te ou timeout 5s
- ‚úÖ **Buffer glissant 60 secondes** : Maintient le contexte des derni√®res 60 secondes
- ‚úÖ **Format JSON strict** : Utilise `format='json'` dans l'appel Ollama
- ‚úÖ **Context window** : `num_ctx: 4096` pour plus de contexte
- ‚úÖ **D√©tection de phrase compl√®te** : Analyse quand phrase se termine (., !, ?)

**Structure :**
```python
# Accumulation avec timeout
self._accumulation_timeout = 5.0  # seconds
self._context_window_seconds = 60.0  # Buffer glissant

# Appel Ollama avec JSON strict
response = ollama.chat(
    model=self.config.ollama_model,
    messages=[...],
    format='json',  # Force JSON
    options={'num_ctx': 4096}
)
```

### 4. `src/osc_client.py` - V√©rifi√© ‚úÖ

**D√©j√† conforme :**
- ‚úÖ Envoie `/visual/prompt` (string)
- ‚úÖ Envoie `/visual/json` (string JSON complet)
- ‚úÖ Thread-safe avec verrous

### 5. `requirements.txt` - Mise √† Jour

**Ajout :**
```txt
moshi>=0.1.0
```

### 6. `main.py` - V√©rifi√© ‚úÖ

**D√©j√† conforme :**
- ‚úÖ Threads daemon (`daemon=True` dans AudioEngine et BrainEngine)
- ‚úÖ Queue partag√©e entre AudioEngine et BrainEngine
- ‚úÖ Int√©gration compl√®te avec UI

## üìã Configuration Requise

### Variables d'environnement (.env)

```env
# Audio Configuration (CRITIQUE pour Moshi)
AUDIO_SAMPLE_RATE=24000  # ‚ö†Ô∏è DOIT √™tre 24000 Hz
AUDIO_CHANNELS=1
AUDIO_CHUNK_SIZE=1920

# Moshi Configuration
MOSHI_DEVICE=mps  # "mps" pour Apple Silicon, "cpu" pour fallback

# Ollama Configuration
OLLAMA_MODEL=qwen2.5
BRAIN_ANALYSIS_INTERVAL=6.0
```

## üöÄ Installation

### 1. Installer Moshi

```bash
# Option 1: Via pip (si disponible)
pip install moshi

# Option 2: Depuis GitHub
pip install git+https://github.com/kyutai-labs/moshi.git

# Option 3: V√©rifier la documentation officielle
# https://github.com/kyutai-labs/moshi
```

### 2. V√©rifier PyTorch avec MPS

```bash
python -c "import torch; print(torch.backends.mps.is_available())"
# Doit afficher: True
```

### 3. Installer toutes les d√©pendances

```bash
pip install -r requirements.txt
```

## üîß Points d'Attention

### 1. API Moshi - Format du Packet

L'API Moshi peut retourner le packet sous diff√©rents formats :
- Objet avec attribut `.text`
- Dictionnaire avec cl√© `'text'`
- String directe

Le code g√®re ces trois cas dans `_audio_callback()`.

### 2. Device Fallback

Le code tente automatiquement MPS, puis CPU si MPS √©choue :
```python
if device_preference == "mps":
    if torch.backends.mps.is_available():
        return "mps"
    else:
        return "cpu"  # Fallback automatique
```

### 3. Sample Rate Critique

‚ö†Ô∏è **IMPORTANT** : Moshi n√©cessite **24000 Hz**. Ne pas utiliser 16000 Hz.

### 4. Chunk Size Optimis√©

Pour 24000 Hz, un chunk de 1920 samples = 80ms, ce qui est optimal pour le streaming.

## üêõ D√©pannage

### Erreur: "moshi package not found"

```bash
pip install moshi
# ou
pip install git+https://github.com/kyutai-labs/moshi.git
```

### Erreur: "MPS not available"

V√©rifier PyTorch avec support MPS :
```bash
pip install torch torchaudio
python -c "import torch; print(torch.backends.mps.is_available())"
```

### Erreur: "Failed to load Moshi model"

1. V√©rifier la connexion internet (t√©l√©chargement du mod√®le)
2. V√©rifier l'espace disque (mod√®le ~2-3 GB)
3. Essayer avec device="cpu" en fallback

### Transcription ne fonctionne pas

1. V√©rifier les permissions microphone dans macOS
2. V√©rifier que `sample_rate=24000` dans la config
3. V√©rifier les logs dans la console pour erreurs Moshi

## üìä Flux de Donn√©es

```
Microphone (24000 Hz)
    ‚Üì
sounddevice callback
    ‚Üì
numpy array ‚Üí torch tensor
    ‚Üì
worker.feed_audio(tensor)
    ‚Üì
worker.get_output() ‚Üí packet.text
    ‚Üì
text_queue (thread-safe)
    ‚Üì
BrainEngine (accumulation + buffer 60s)
    ‚Üì
Ollama (format='json', num_ctx=4096)
    ‚Üì
OSC Client (/visual/prompt, /visual/json)
```

## ‚úÖ Checklist de Test

- [ ] Moshi install√© et importable
- [ ] PyTorch avec MPS disponible
- [ ] Sample rate configur√© √† 24000 Hz
- [ ] Permissions microphone accord√©es
- [ ] Ollama install√© avec mod√®le qwen2.5
- [ ] Test audio callback fonctionne
- [ ] Test transcription Moshi fonctionne
- [ ] Test OSC envoi fonctionne
- [ ] Buffer glissant 60s fonctionne
- [ ] Format JSON strict fonctionne

## üìö Ressources

- [Moshi GitHub](https://github.com/kyutai-labs/moshi)
- [PyTorch MPS](https://pytorch.org/docs/stable/notes/mps.html)
- [Ollama Python](https://github.com/ollama/ollama-python)

