# Development History

## Overview
This document consolidates the full chronological history of the **VoceVibe4** project migration from the MLX‚Äëbased STT backend to the official PyTorch `kyutai/stt-1b-en_fr` model.

It combines the original implementation plan, the detailed walkthrough, and the task checklist, providing a single reference for future maintenance.

---

### Implementation Plan (original)

* **Objective**: Migrate to PyTorch STT model for deterministic, hallucination‚Äëfree French transcription.
* **Key Steps**:
  1. Remove MLX dependencies and install PyTorch, Moshi, and related packages.
  2. Create `download_stt.py` to fetch model files from HuggingFace.
  3. Rewrite `src/audio_engine.py` to load the model via Moshi, handle audio encoding with Mimi, and enforce `temp=0.0`.
  4. Verify on CPU, ensure correct sample rate (24‚ÄØkHz), and maintain producer‚Äëconsumer queue.

---

### Walkthrough (summary)

* **Dependencies**: Uninstalled `moshi_mlx`, `mlx`, `rustymimi`; installed `torch==2.5.1`, `torchaudio==2.5.1`, `moshi`, `huggingface‚Äëhub`, `sentencepiece`, `sounddevice`.
* **Model Download**: `download_stt.py` successfully retrieves `model.safetensors`, `config.json`, `tokenizer_spm_32k_3.model`, and related files.
* **Audio Engine Rewrite**:
  * Loaded model configuration, filtered incompatible keys, and instantiated via `loaders.get_moshi_lm`.
  * Initialized Mimi with `num_codebooks=32`.
  * Implemented streaming context (`with self.lm_gen.streaming(batch_size=1):`).
  * Fixed gradient error by removing `torch.no_grad()` around `lm_gen.step`.
  * **System Prompt Optimization**: Updated `BrainEngine` system prompt to enforce English output, specific SDXL-Turbo syntax (`[Style], [Subject], ...`), and strict JSON format for better visual generation.
* **Verification**:
  * `test_stt_final.py` confirmed model loads and processes dummy audio chunks.
  * `main.py` runs without errors, providing French transcriptions.

---

### Task Checklist (final state)

```
- [x] Uninstall MLX dependencies
- [x] Install PyTorch dependencies (torch 2.5.1, torchaudio 2.5.1, moshi, etc.)
- [x] Update requirements.txt
- [x] Create and run download_stt.py
- [x] Rewrite audio_engine.py for PyTorch CPU
- [x] Configure deterministic decoding (temp=0.0)
- [x] Fix streaming context and Mimi codebook count
- [x] Remove erroneous torch.no_grad() wrapper
- [x] Verify with test script and main application
- [x] Clean up repository (remove tests, add README, update .gitignore, set main branch)
```

---

## Future Work
* Explore GPU acceleration (if compatible hardware becomes available).
* Add unit tests for audio processing pipeline.
* Integrate UI improvements and dynamic visual feedback.
# üìú Historique d'Impl√©mentation - Kyutai STT (Moshi/Moshika) sur macOS

## üéØ Contexte du Projet

### VoiceVibe4 - Performance Visuelle en Temps R√©el

**Objectif** : Cr√©er une application macOS native qui transforme la voix en performances visuelles en temps r√©el.

**Architecture** :
- **AudioEngine** : Capture microphone ‚Üí Transcription STT ‚Üí Queue texte
- **BrainEngine** : Analyse texte (LLM local) ‚Üí G√©n√©ration prompts visuels ‚Üí OSC vers PC distant
- **Interface** : GUI customtkinter avec visualisation temps r√©el

**Exigence STT** :
- Transcription bilingue fran√ßais/anglais en temps r√©el
- Optimis√© Apple Silicon (M1/M2/M3)
- Latence minimale pour performance live
- Pas de Whisper (trop lent, pas de streaming natif)

**Choix initial** : **Kyutai Moshi** (mod√®le 1B bilingue fr/en, streaming natif, optimis√© Apple Silicon)

---

## üó∫Ô∏è Parcours d'Impl√©mentation - √âtape par √âtape

### **√âtape 1 : Impl√©mentation PyTorch Initiale**

#### Configuration
- **Mod√®le** : `kyutai/moshiko-pytorch-bf16`
- **Backend** : PyTorch avec MPS (Metal Performance Shaders)
- **Sample Rate** : 24000 Hz
- **Chunk Size** : 1920 samples (80 ms @ 24 kHz)
- **Device** : MPS avec fallback CPU

#### Probl√®me #1 : API Incorrecte
```
ImportError: cannot import name 'MoshiLoader' from 'moshi.models.loaders'
```

**Cause** : Tentative d'utiliser une API inexistante (`MoshiLoader`, `get_worker()`)

**Solution tent√©e** : Recherche de la bonne API dans la documentation

**R√©sultat** : D√©couverte de `moshi.models.loaders.get_moshi_lm` et `LMGen`

---

### **√âtape 2 : Correction API PyTorch**

#### Configuration
- **Mod√®le** : `kyutai/moshiko-pytorch-bf16`
- **API** : `get_moshi_lm()` + `LMGen` pour streaming
- **Architecture** : Callback audio direct ‚Üí Encodage ‚Üí Inf√©rence ML

#### Probl√®me #2 : Crash PyTorch MPS
```
SIGABRT: libtorch_python.dylib
c10::StorageImpl::~StorageImpl()
```

**Cause** : Gestion m√©moire PyTorch MPS d√©faillante, tensors non lib√©r√©s correctement

**Solutions tent√©es** :
1. Ajout de `torch.no_grad()` autour de l'inf√©rence
2. `.detach()` sur tous les tensors
3. `del` explicite des tensors
4. `torch.mps.empty_cache()` apr√®s chaque batch
5. `non_blocking=True` pour les transfers device

**R√©sultat** : Crash toujours pr√©sent, instabilit√© MPS

---

### **√âtape 3 : Fallback CPU PyTorch**

#### Configuration
- **Mod√®le** : `kyutai/moshiko-pytorch-bf16`
- **Device** : CPU (fallback forc√©)
- **Variable** : `PYTORCH_ENABLE_MPS_FALLBACK=1`

#### Probl√®me #3 : Op√©rateur MPS Non Impl√©ment√©
```
The operator 'aten::index_copy.out' is not currently implemented for the MPS device.
```

**Cause** : PyTorch MPS ne supporte pas tous les op√©rateurs n√©cessaires √† Moshi

**Solution** : Forcer CPU avec `PYTORCH_ENABLE_MPS_FALLBACK=1`

**R√©sultat** : Fonctionne mais **performance terrible** (CPU trop lent pour temps r√©el)

---

### **√âtape 4 : Probl√®me de Transcription**

#### Configuration
- **Mod√®le** : `kyutai/moshiko-pytorch-bf16`
- **Device** : CPU (fallback)
- **Performance** : Lente mais fonctionnelle

#### Probl√®me #4 : Transcription Inexacte
- Transcription en anglais alors que l'input est fran√ßais (France Culture)
- Hallucinations : "Hey there, how is it going?" au lieu de transcription
- Mod√®le refuse de transcrire en fran√ßais

**Cause** : 
1. Biais linguistique vers l'anglais par d√©faut
2. Pas de conditionnement linguistique
3. Signal audio peut-√™tre trop faible

**Solutions tent√©es** :
1. V√©rification du mod√®le : `kyutai/stt-1b-en_fr` (bilingue confirm√©)
2. Augmentation du volume source
3. Tentative de conditionnement fran√ßais (√©chec - crash dimensions)

**R√©sultat** : Mod√®le transcrit mais avec biais anglais fort

---

### **√âtape 5 : Migration vers Moshi MLX**

#### D√©cision
**Raison** : PyTorch MPS instable, CPU trop lent ‚Üí Passage √† **MLX** (framework natif Apple Silicon)

#### Configuration Initiale
- **Mod√®le** : `kyutai/moshiko-mlx-q4` (4-bit quantization)
- **Backend** : MLX (Metal optimis√©)
- **Packages** : `moshi_mlx`, `rustymimi`, `mlx.core`
- **Sample Rate** : 24000 Hz
- **Chunk Size** : 1920 samples

#### Impl√©mentation
- Architecture producteur-consommateur (queue audio)
- Encodage avec `rustymimi.StreamTokenizer`
- Inf√©rence avec `models.LmGen.step()`
- D√©codage avec `sentencepiece.SentencePieceProcessor`

#### Probl√®me #5 : Hallucinations et R√©ponses IA
```
STT: "How can I help you"
STT: "That's correct"
```

**Cause** : 
1. Le mod√®le g√©n√®re √† la fois transcription ET r√©ponses IA
2. Pas de filtrage des tokens (on capture tout)
3. Temp√©rature trop √©lev√©e (d√©faut ~0.8)

**Solutions tent√©es** :
1. R√©duction temp√©rature : `temp=0.2` ‚Üí `temp=0.1`
2. Ajout `top_p=0.9` pour √©liminer tokens improbables
3. Noise gate strict : seuil 0.04 (ignore bruit de fond)

**R√©sultat** : Moins d'hallucinations mais toujours des r√©ponses IA m√©lang√©es

---

### **√âtape 6 : Filtrage des Tokens**

#### Configuration
- **Mod√®le** : `kyutai/moshiko-mlx-q4`
- **Sampling** : `temp=0.1`, `top_p=0.9`
- **Noise Gate** : 0.04

#### Probl√®me #6 : M√©lange Transcription/R√©ponses IA
Le mod√®le g√©n√®re deux types de tokens :
- **Tokens transcription** : Ce que l'utilisateur dit
- **Tokens r√©ponse IA** : R√©ponses de Moshi ("How can I help you", etc.)

**Cause** : Pas de distinction dans le code entre les deux types de tokens

**Solution** : **D√©couverte cruciale** - Dans `moshi_mlx.local`, les tokens 0 et 3 sont filtr√©s :
```python
if text_token_id not in (0, 3):
    # C'est un token de transcription valide
```

**R√©sultat** : Filtrage impl√©ment√©, mais probl√®me persiste (tokens IA passent quand m√™me)

---

### **√âtape 7 : Conditionnement Fran√ßais (√âchec)**

#### Configuration
- **Mod√®le** : `kyutai/moshiko-mlx-q4`
- **Objectif** : Forcer le mod√®le en mode fran√ßais

#### Probl√®me #7 : Biais Anglais Persistant
Le mod√®le refuse de transcrire en fran√ßais, m√™me avec France Culture

**Solution tent√©e** : Conditionnement fran√ßais
```python
# Pr√©-remplir le contexte avec du fran√ßais
prompt_text = "Transcription en fran√ßais : "
# Encoder et injecter dans le mod√®le
```

#### Probl√®me #8 : Crash Dimensions
```
Error: (1,8,1,1) vs (1,8,1) - dimension mismatch
```

**Cause** : Mauvaise forme des tensors MLX pour le conditionnement

**R√©sultat** : Conditionnement abandonn√© (trop complexe, instable)

---

### **√âtape 8 : Passage √† Moshika**

#### D√©cision
**Raison** : Moshika (voix f√©minine) souvent plus stable que Moshiko pour la transcription

#### Configuration
- **Mod√®le** : `kyutai/moshika-mlx-q4` (au lieu de `moshiko`)
- **Backend** : MLX
- **Quantization** : 4-bit (q4)

#### Probl√®me #9 : Signal Audio Faible
Transcription instable, mod√®le hallucine √† cause du bruit de fond

**Solutions** :
1. **AGC Plus Agressif** : `target_level=0.95` (au lieu de 0.8)
2. **Warning Signal Faible** : Alerte si `peak < 0.05`
3. **Noise Gate Strict** : Seuil 0.04 maintenu

**R√©sultat** : Meilleure normalisation, mais probl√®me de tokens IA persiste

---

### **√âtape 9 : D√©couverte du Pattern Officiel**

#### R√©alisation
Le code manuel √©tait instable ‚Üí **Utiliser le pattern de `moshi_mlx.local`**

#### Analyse de `moshi_mlx.local`
- Architecture client-serveur avec queues
- Filtrage strict : `if text_token_id not in (0, 3)`
- Transposition exacte : `mx.array(data).transpose(1, 0)[:, :8]`
- Pas de conditionnement complexe

#### Probl√®me #10 : Impl√©mentation Manuelle Instable
- Lecture des mauvais tokens (r√©ponses IA au lieu de transcription)
- Dimensions incorrectes
- Architecture trop complexe

**Solution** : **R√©√©criture compl√®te** bas√©e sur `moshi_mlx.local`

---

### **√âtape 10 : R√©√©criture avec Pattern Officiel (Solution Finale)**

#### Configuration Finale
- **Mod√®le** : `kyutai/moshika-mlx-q4`
- **Pattern** : Bas√© sur `moshi_mlx.local` (r√©f√©rence officielle)
- **Architecture** : Producteur-consommateur avec queue
- **Filtrage** : Tokens 0 et 3 ignor√©s (filtre r√©ponses IA)
- **Sampling** : `temp=0.1`, `top_p=0.9` (strict)
- **AGC** : `target_level=0.95` (agressif)
- **Noise Gate** : 0.04 (strict)

#### Impl√©mentation Cl√©
```python
# Filtrage strict (pattern officiel)
if text_token_id not in (0, 3):
    # Token de transcription valide
    text_piece = text_tokenizer.id_to_piece(text_token_id)
    text_piece = text_piece.replace("‚ñÅ", " ")
    # Ajouter √† la queue
```

#### Transposition Exacte (Pattern Officiel)
```python
# Comme dans moshi_mlx.local
data = mx.array(encoded_data).transpose(1, 0)[:, :8]
text_token = self.gen.step(data)
```

**R√©sultat** : ‚úÖ **Solution stable et fonctionnelle**

---

## üìä R√©capitulatif des Configurations Test√©es

| √âtape | Mod√®le | Backend | Device | Chunk Size | Sampling | R√©sultat |
|-------|--------|---------|--------|------------|----------|----------|
| 1 | moshiko-pytorch-bf16 | PyTorch | MPS | 1920 | D√©faut | ‚ùå API incorrecte |
| 2 | moshiko-pytorch-bf16 | PyTorch | MPS | 1920 | D√©faut | ‚ùå Crash MPS |
| 3 | moshiko-pytorch-bf16 | PyTorch | CPU | 1920 | D√©faut | ‚ö†Ô∏è Trop lent |
| 4 | moshiko-pytorch-bf16 | PyTorch | CPU | 1920 | D√©faut | ‚ö†Ô∏è Biais anglais |
| 5 | moshiko-mlx-q4 | MLX | MLX | 1920 | D√©faut | ‚ö†Ô∏è Hallucinations |
| 6 | moshiko-mlx-q4 | MLX | MLX | 1920 | temp=0.1 | ‚ö†Ô∏è Tokens IA |
| 7 | moshiko-mlx-q4 | MLX | MLX | 1920 | temp=0.1 | ‚ùå Crash conditionnement |
| 8 | moshika-mlx-q4 | MLX | MLX | 1920 | temp=0.1 | ‚ö†Ô∏è Signal faible |
| 9 | moshika-mlx-q4 | MLX | MLX | 1920 | temp=0.1 | ‚ö†Ô∏è Pattern incorrect |
| 10 | **moshika-mlx-q4** | **MLX** | **MLX** | **1920** | **temp=0.1, top_p=0.9** | ‚úÖ **Stable** |

---

## üîë Le√ßons Apprises

### 1. **PyTorch MPS n'est pas pr√™t pour Moshi**
- Op√©rateurs manquants (`aten::index_copy.out`)
- Gestion m√©moire instable
- **Solution** : MLX (framework natif Apple Silicon)

### 2. **Le Filtrage des Tokens est Critique**
- Tokens 0 et 3 = tokens sp√©ciaux (padding, etc.)
- Sans filtrage ‚Üí r√©ponses IA m√©lang√©es avec transcription
- **Solution** : Pattern officiel avec `if text_token_id not in (0, 3)`

### 3. **L'Architecture Producteur-Consommateur est Essentielle**
- Callback audio doit √™tre ultra-l√©ger
- Traitement ML dans thread s√©par√©
- **Solution** : Queue pour d√©coupler capture et inf√©rence

### 4. **Le Pattern Officiel est la R√©f√©rence**
- `moshi_mlx.local` = impl√©mentation de r√©f√©rence
- Transposition exacte : `.transpose(1, 0)[:, :8]`
- **Solution** : Suivre le pattern officiel √† la lettre

### 5. **Moshika est Plus Stable que Moshiko**
- Moshika (voix f√©minine) = meilleure transcription
- Moshiko = plus de r√©ponses IA parasites
- **Solution** : Utiliser Moshika pour STT pur

### 6. **Le Sampling Strict R√©duit les Hallucinations**
- Temp√©rature basse (0.1) = d√©terministe
- `top_p=0.9` = √©limine tokens improbables
- **Solution** : Sampling strict pour STT

### 7. **L'AGC Agressif Am√©liore la Transcription**
- Signal faible ‚Üí hallucinations
- `target_level=0.95` = meilleure normalisation
- **Solution** : AGC agressif avec warning signal faible

### 8. **Le Noise Gate Strict √âvite le Bruit**
- Bruit de fond ‚Üí hallucinations
- Seuil 0.04 = ignore bruit, garde voix
- **Solution** : Noise gate strict avec `continue` (skip chunk)

---

## üéØ Configuration Finale Recommand√©e

### Mod√®le
- **Repo** : `kyutai/moshika-mlx-q4`
- **Quantization** : 4-bit (q4) - bon compromis vitesse/qualit√©
- **Backend** : MLX (Metal optimis√©)

### Audio
- **Sample Rate** : 24000 Hz (requis par Mimi)
- **Chunk Size** : 1920 samples (80 ms @ 24 kHz)
- **Channels** : 1 (mono)

### Traitement
- **AGC** : `target_level=0.95`, `max_gain=8.0`
- **Noise Gate** : `threshold=0.04`
- **Warning** : Si `peak < 0.05` ‚Üí alerte utilisateur

### Mod√®le MLX
- **Sampling** : `temp=0.1`, `top_p=0.9` (strict)
- **Filtrage** : Tokens 0 et 3 ignor√©s
- **Pattern** : Bas√© sur `moshi_mlx.local`

### Architecture
- **Producteur** : Callback audio ‚Üí Queue (ultra-l√©ger)
- **Consommateur** : Queue ‚Üí Encodage ‚Üí Inf√©rence ‚Üí Filtrage ‚Üí Queue texte

---

## üìù Notes Finales

### Ce qui Fonctionne ‚úÖ
- Transcription bilingue fr/en en temps r√©el
- Latence acceptable pour performance live
- Stable sur Apple Silicon (MLX)
- Filtrage correct des tokens (pas de r√©ponses IA)

### Limitations Actuelles ‚ö†Ô∏è
- Biais linguistique vers l'anglais (pas de conditionnement linguistique)
- N√©cessite signal audio fort (AGC + noise gate)
- Pas de support multilingue explicite (d√©tection auto)

### Am√©liorations Futures üîÆ
- Conditionnement linguistique stable (fran√ßais/anglais)
- D√©tection automatique de langue
- Support de plus de langues
- Optimisation m√©moire pour sessions longues

---

## üìö R√©f√©rences

- **Moshi MLX** : https://github.com/kyutai/moshi-mlx
- **Pattern Officiel** : `moshi_mlx.local` (dans package install√©)
- **Documentation Kyutai** : https://huggingface.co/kyutai
- **MLX Framework** : https://github.com/ml-explore/mlx

---

**Date de derni√®re mise √† jour** : 2024-11-24  
**Version** : Finale (bas√©e sur pattern officiel)  
**Statut** : ‚úÖ Stable et fonctionnel

